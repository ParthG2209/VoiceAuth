# ğŸ™ï¸ VoiceAuth - AI Voice Detection API

Detect whether a voice sample is **AI-generated** or **Human** across 5 languages using ensemble ML models.

## ğŸŒ Supported Languages
- Tamil
- English  
- Hindi
- Malayalam
- Telugu

## ğŸ§  Detection Methods
1. **Feature-based Analysis** - MFCC, pitch, spectral, energy patterns
2. **Wav2Vec2 Deep Learning** - Facebook's pre-trained speech model
3. **Ensemble Voting** - Combines both methods for best accuracy

---

## ğŸš€ Quick Start (Local Testing)

### Prerequisites
- Python 3.10+ 
- FFmpeg (for audio processing)

### Option 1: Automated Setup (Recommended)

```bash
# 1. Clone the repository
git clone https://github.com/ParthG2209/VoiceAuth.git
cd VoiceAuth

# 2. Run setup script
./setup.sh

# 3. Activate virtual environment
source venv/bin/activate

# 4. Start the server
./run.sh
```

### Option 2: Manual Setup

```bash
# 1. Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 2. Install dependencies
pip install --upgrade pip
pip install -r requirements.txt

# 3. Create directories
mkdir -p models data/sample_audio logs

# 4. Set up environment
cp .env.example .env
# Edit .env and update your API_KEY

# 5. Run the server
uvicorn app.main:app --reload --port 8000
```

---

## ğŸ“¡ API Usage

### Base URL
```
http://localhost:8000
```

### Endpoints

#### 1. Health Check
```bash
curl http://localhost:8000/api/health
```

#### 2. Voice Detection
```bash
curl -X POST "http://localhost:8000/api/voice-detection?use_deep_learning=true" \
  -H "Content-Type: application/json" \
  -H "x-api-key: sk_voiceauth_dev_key_12345" \
  -d '{
    "language": "English",
    "audioFormat": "mp3",
    "audioBase64": "YOUR_BASE64_ENCODED_MP3"
  }'
```

**Query Parameters:**
- `use_deep_learning` (optional, default: `true`)
  - `true` - Use Wav2Vec2 + features (more accurate, slower first time)
  - `false` - Use features only (faster)

**Response:**
```json
{
  "status": "success",
  "language": "English",
  "classification": "AI_GENERATED",
  "confidenceScore": 0.87,
  "explanation": "Low temporal variation in speech embeddings; High frame-to-frame consistency"
}
```

---

## ğŸ§ª Testing

### Run Test Suite
```bash
# Make sure server is running first
source venv/bin/activate
python test_local.py
```

This will test:
- âœ… Health check endpoint
- âœ… API authentication
- âœ… Voice detection (feature-based)
- âœ… Voice detection (deep learning)
- âœ… All 5 supported languages

### Run Unit Tests
```bash
pytest tests/ -v
```

---

## ğŸ“š API Documentation

Once the server is running, visit:
- **Swagger UI:** http://localhost:8000/docs
- **ReDoc:** http://localhost:8000/redoc

---

## ğŸ”‘ Authentication

All endpoints (except `/health`) require the `x-api-key` header:

```bash
x-api-key: YOUR_API_KEY
```

Set your API key in `.env`:
```bash
API_KEY=sk_voiceauth_your_secret_key_here
```

---

## ğŸ“ Project Structure

```
VoiceAuth/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ auth.py              # API key validation
â”‚   â”‚   â”œâ”€â”€ routes.py            # API endpoints
â”‚   â”‚   â””â”€â”€ schemas.py           # Request/Response models
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ detector.py          # Feature-based detector
â”‚   â”‚   â”œâ”€â”€ wav2vec2_detector.py # Deep learning detector
â”‚   â”‚   â””â”€â”€ ensemble.py          # Ensemble combining both
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ audio_processor.py   # Audio processing pipeline
â”‚   â”œâ”€â”€ config.py                # Configuration
â”‚   â””â”€â”€ main.py                  # FastAPI app
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_api.py              # API tests
â”œâ”€â”€ models/                      # Downloaded ML models (auto-created)
â”œâ”€â”€ setup.sh                     # Setup script
â”œâ”€â”€ run.sh                       # Run server script
â”œâ”€â”€ test_local.py                # Local testing script
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## ğŸ³ Docker Deployment

```bash
# Build and run with Docker Compose
docker-compose up --build

# Or with Docker directly
docker build -t voiceauth .
docker run -p 8000:8000 -e API_KEY=your_key voiceauth
```

---

## âš™ï¸ Configuration

Edit `.env` file:

```bash
# API Security
API_KEY=sk_voiceauth_your_secret_key_here

# Server
HOST=0.0.0.0
PORT=8000
DEBUG=true

# Models
MODEL_CACHE_DIR=./models
USE_GPU=false

# Audio Limits
MAX_AUDIO_SIZE_MB=10
MAX_AUDIO_DURATION_SECONDS=60
```

---

## ğŸ“Š Model Performance

### First Request (Wav2Vec2 Download)
- Downloads ~360MB model from Hugging Face
- Takes 1-2 minutes (one-time only)
- Cached in `./models/` for future use

### Subsequent Requests
- Feature-based: ~0.5-1s
- With Wav2Vec2: ~2-3s
- Ensemble: ~2-3s

---

## ğŸ”§ Troubleshooting

### Server won't start
```bash
# Check if port 8000 is in use
lsof -i :8000

# Use a different port
uvicorn app.main:app --port 8080
```

### Dependencies installation fails
```bash
# Install system dependencies (macOS)
brew install ffmpeg

# Install system dependencies (Ubuntu)
sudo apt-get install ffmpeg libsndfile1
```

### Wav2Vec2 download fails
```bash
# Set Hugging Face cache directory
export HF_HOME=./models
export TRANSFORMERS_CACHE=./models
```

---

## ğŸ¯ Supported Audio Formats

- **Input:** MP3 (Base64 encoded)
- **Sample Rate:** Automatically resampled to 16kHz
- **Max Duration:** 60 seconds (configurable)
- **Max Size:** 10MB (configurable)

---

## ğŸ“ Example: Convert Audio to Base64

### Python
```python
import base64

with open("audio.mp3", "rb") as f:
    audio_base64 = base64.b64encode(f.read()).decode()
```

### Command Line
```bash
base64 -i audio.mp3 -o audio.txt
```

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests: `pytest tests/`
5. Submit a pull request

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸ”— Links

- **GitHub:** https://github.com/ParthG2209/VoiceAuth
- **API Docs:** http://localhost:8000/docs (when running)

---

## ğŸ’¡ Tips

1. **First run with Wav2Vec2** will download the model (~360MB)
2. Use `use_deep_learning=false` for faster testing
3. Check logs in console for detailed processing info
4. Use Swagger UI for interactive API testing

---

**Built with â¤ï¸ using FastAPI, Hugging Face Transformers, and Librosa**
